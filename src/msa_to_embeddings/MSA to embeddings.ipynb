{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b339915",
   "metadata": {},
   "source": [
    "# Transform MSAs the corresponding embeddings of the MSA Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "043d96e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import esm\n",
    "import torch\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "import itertools\n",
    "from typing import List, Tuple\n",
    "import string\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c55b817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f69b043b820>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4812344d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is an efficient way to delete lowercase characters and insertion characters from a string\n",
    "deletekeys = dict.fromkeys(string.ascii_lowercase)\n",
    "deletekeys[\".\"] = None\n",
    "deletekeys[\"*\"] = None\n",
    "translation = str.maketrans(deletekeys)\n",
    "\n",
    "def read_sequence(filename: str) -> Tuple[str, str]:\n",
    "    \"\"\" Reads the first (reference) sequences from a fasta or MSA file.\"\"\"\n",
    "    record = next(SeqIO.parse(filename, \"fasta\"))\n",
    "    return record.description, str(record.seq)\n",
    "\n",
    "def remove_insertions(sequence: str) -> str:\n",
    "    \"\"\" Removes any insertions into the sequence. Needed to load aligned sequences in an MSA. \"\"\"\n",
    "    return sequence.translate(translation)\n",
    "\n",
    "def read_msa(filename: str, nseq: int) -> List[Tuple[str, str]]:\n",
    "    \"\"\" Reads the first nseq sequences from an MSA file, automatically removes insertions.\"\"\"\n",
    "    return [(record.description, remove_insertions(str(record.seq)))\n",
    "            for record in itertools.islice(SeqIO.parse(filename, \"fasta\"), nseq)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "298ef2b8",
   "metadata": {},
   "source": [
    "## Import the MSA Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d69ded6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ea4b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This can that a while to download (1.3Gb)= but once done, it's kept in memory\n",
    "msa_transformer, msa_alphabet = esm.pretrained.esm_msa1b_t12_100M_UR50S()\n",
    "msa_transformer = msa_transformer.eval()\n",
    "msa_batch_converter = msa_alphabet.get_batch_converter()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b950f5d9",
   "metadata": {},
   "source": [
    "## Read  MSA file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08a13008",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_seqs_per_msa = 100\n",
    "NB_msa= 4431\n",
    "#mb_layers = [i for i in range(1,13)] #we get all the intermediate layers at once\n",
    "Emb_layers = [2,6,11]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95489597",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_MSAs = \"C:/Users/caspe/PycharmProjects/NLP/MSA_a3m/\" #where to read the MSAs\n",
    "EMBEDDINGS_PATH = \"C:/Users/caspe/PycharmProjects/NLP/MSA_embeddings/\" #where to save the embeddings\n",
    "if not(os.path.isdir(EMBEDDINGS_PATH+'MSA_transformer_embeddings')):\n",
    "    os.mkdir(EMBEDDINGS_PATH+'MSA_transformer_embeddings')\n",
    "EMBEDDINGS_PATH += 'MSA_transformer_embeddings/' #create a new folder to save the embeddings\n",
    "\n",
    "\n",
    "MSAs = os.listdir(PATH_TO_MSAs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9a1fa1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3032\n"
     ]
    }
   ],
   "source": [
    "print(len(MSAs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7263bc9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# format MSA string as needed\n",
    "#for f in MSAs:\n",
    "#    with open(PATH_TO_MSAs+f, \"r\") as msa_file:\n",
    "#        content = msa_file.read()\n",
    "\n",
    "#    content = content.replace(\">\", \">\\n\")\n",
    "#    with open(PATH_TO_MSAs+f, \"w\") as msa_file:\n",
    "#        msa_file.write(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e92e0e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10, 184]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "msa_data = [\n",
    "    read_msa(PATH_TO_MSAs+f, NB_seqs_per_msa) for f in MSAs\n",
    "]\n",
    "msa_batch_labels, msa_batch_strs, msa_batch_tokens = msa_batch_converter(msa_data)\n",
    "msa_batch_tokens = msa_batch_tokens\n",
    "print(msa_batch_tokens.size(), msa_batch_tokens.dtype)\n",
    "# Should be a 3D tensor with dtype torch.int64. of shape NB_SEQ, SIZE_MSA, MAX_LEN_SEQ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decd9d3b",
   "metadata": {},
   "source": [
    "## Run the MSA transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "723b512d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.317943334579468\n"
     ]
    }
   ],
   "source": [
    "# Set up GPU\n",
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "\n",
    "\n",
    "#msa_batch_tokens = msa_batch_tokens.to(device)\n",
    "#print(msa_batch_tokens.is_cuda)\n",
    "\n",
    "msa_transformer = msa_transformer.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06eab577",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10, 184, 768])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#torch.cuda.empty_cache()\n",
    "#torch.cuda.memory_stats(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1591c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "t1 = time.time()\n",
    "for i in tqdm(range(len(MSAs))):\n",
    "    msa_name = str(MSAs[i:i+1][0][:-4])\n",
    "    os.mkdir(EMBEDDINGS_PATH+msa_name)\n",
    "    msa_data = [read_msa(PATH_TO_MSAs+f, NB_seqs_per_msa) for f in MSAs[i:i+1]]\n",
    "    msa_batch_labels, msa_batch_strs, msa_batch_tokens = msa_batch_converter(msa_data)\n",
    "    torch.cuda.empty_cache()\n",
    "    msa_batch_tokens = msa_batch_tokens.to(device)\n",
    "    results = msa_transformer(msa_batch_tokens, repr_layers=Emb_layers)\n",
    "    embeddings = [results[\"representations\"][emb_layer][:,0,:,:].clone() for emb_layer in Emb_layers]\n",
    "    for emb_layer in Emb_layers:\n",
    "        torch.save(embeddings, EMBEDDINGS_PATH+msa_name+'/embeddings_layer_'+str(emb_layer)+'_MSA_Transformer.pt')\n",
    "\n",
    "t2 = time.time()\n",
    "print(t2-t1)\n",
    "\n",
    "# this is the long part ...\n",
    "# It's possible that we should break msa_batch_tokens in smaller part to fit in the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "027dc2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results[\"representations\"][1].shape\n",
    "#should be of size [NB_SEQ, SIZE_MSA, MAX_lEN, 768] (768=dimension of the embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a9132ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#we keep only the first dimension along the second axis\n",
    "\n",
    "embeddings = [results[\"representations\"][emb_layer][:,0,:,:].clone() for emb_layer in Emb_layers]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for emb_layer in Emb_layers:\n",
    "    torch.save(embeddings, EMBEDDINGS_PATH+'embeddings_layer_'+str(emb_layer)+'_MSA_Transformer.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protein-transformer",
   "language": "python",
   "name": "protein-transformer"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}